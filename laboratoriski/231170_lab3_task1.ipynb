{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-08T21:26:48.401305Z",
     "start_time": "2025-12-08T21:26:42.565885Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from evaluate import load\n",
    "from seq2seq import create_transformers_train_data, train_transformer, decode_with_transformer"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arsan\\PycharmProjects\\opj\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:26:48.432046Z",
     "start_time": "2025-12-08T21:26:48.405310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "a242118ae2d8eb0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:26:48.572686Z",
     "start_time": "2025-12-08T21:26:48.558404Z"
    }
   },
   "cell_type": "code",
   "source": "data = pd.read_csv('../yelp_parallel/yelp_parallel/test_en_parallel.txt', sep='\\t')",
   "id": "6867190353b67938",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:26:48.604052Z",
     "start_time": "2025-12-08T21:26:48.589541Z"
    }
   },
   "cell_type": "code",
   "source": "data.head()",
   "id": "f2eaf95cb0f1a95f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                             Style 1  \\\n",
       "0  ever since joes has changed hands it's just go...   \n",
       "1  there is definitely not enough room in that pa...   \n",
       "2                  so basically tasted watered down.   \n",
       "3  she said she'd be back and disappeared for a f...   \n",
       "4  i can't believe how inconsiderate this pharmac...   \n",
       "\n",
       "                                             Style 2  \n",
       "0  Ever since joes has changed hands it's gotten ...  \n",
       "1    There is so much room in that part of the venue  \n",
       "2              It didn't taste watered down at all.   \n",
       "3  She said she'd be back, and didn't disappear a...  \n",
       "4               This pharmacy is really considerate.  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Style 1</th>\n",
       "      <th>Style 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ever since joes has changed hands it's just go...</td>\n",
       "      <td>Ever since joes has changed hands it's gotten ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>there is definitely not enough room in that pa...</td>\n",
       "      <td>There is so much room in that part of the venue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>so basically tasted watered down.</td>\n",
       "      <td>It didn't taste watered down at all.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she said she'd be back and disappeared for a f...</td>\n",
       "      <td>She said she'd be back, and didn't disappear a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i can't believe how inconsiderate this pharmac...</td>\n",
       "      <td>This pharmacy is really considerate.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:26:48.665940Z",
     "start_time": "2025-12-08T21:26:48.651928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "negative = data[\"Style 1\"].values.tolist()\n",
    "positive = data[\"Style 2\"].values.tolist()"
   ],
   "id": "6bc7957b1742f272",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "T5",
   "id": "1d0cf7bedbdff663"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:26:51.442643Z",
     "start_time": "2025-12-08T21:26:48.697326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bleu = load(\"bleu\")\n",
    "bertscore = load(\"bertscore\")"
   ],
   "id": "d8f6de718caddc88",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:26:51.457913Z",
     "start_time": "2025-12-08T21:26:51.445753Z"
    }
   },
   "cell_type": "code",
   "source": "model_name = \"t5-small\"",
   "id": "37ed6069f35cb38c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:26:52.250202Z",
     "start_time": "2025-12-08T21:26:51.474799Z"
    }
   },
   "cell_type": "code",
   "source": "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)",
   "id": "b1a40b1d668de8d2",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:26:53.130595Z",
     "start_time": "2025-12-08T21:26:52.266402Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = AutoTokenizer.from_pretrained(model_name)",
   "id": "5cd40cc82a1b579a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:26:53.176732Z",
     "start_time": "2025-12-08T21:26:53.146972Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset = create_transformers_train_data(negative, positive, tokenizer)",
   "id": "4f8db089d3fcc88b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arsan\\PycharmProjects\\opj\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:26:53.207456Z",
     "start_time": "2025-12-08T21:26:53.192994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, collate_fn=data_collator)"
   ],
   "id": "7a12c65d30789e60",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:26:53.238109Z",
     "start_time": "2025-12-08T21:26:53.223810Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer = AdamW(model.parameters(), lr=0.001)",
   "id": "2e9bbe8da4534556",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:26:58.082386Z",
     "start_time": "2025-12-08T21:26:53.254433Z"
    }
   },
   "cell_type": "code",
   "source": "train_transformer(model, train_loader, optimizer, 5, device=device)",
   "id": "1ffa91493dafb3ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 2.9907\n",
      "Epoch 2/5, Loss: 2.3558\n",
      "Epoch 3/5, Loss: 2.1473\n",
      "Epoch 4/5, Loss: 2.0050\n",
      "Epoch 5/5, Loss: 1.8778\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:26:58.332599Z",
     "start_time": "2025-12-08T21:26:58.098255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predicted_sentence = decode_with_transformer(negative[0], tokenizer, model)\n",
    "predicted_sentence"
   ],
   "id": "7f63866aec1da9ec",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arsan\\PycharmProjects\\opj\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ever since joes has changed hands'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:26:58.380036Z",
     "start_time": "2025-12-08T21:26:58.365621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reference_sentence = positive[0]\n",
    "reference_sentence"
   ],
   "id": "9678ee5f19a0b93d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ever since joes has changed hands it's gotten better and better.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:26:58.395408Z",
     "start_time": "2025-12-08T21:26:58.383382Z"
    }
   },
   "cell_type": "code",
   "source": "bleu.compute(predictions=[predicted_sentence], references=[reference_sentence])",
   "id": "c5c32cd615986001",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.27952792741962756,\n",
       " 'precisions': [0.8333333333333334, 0.8, 0.75, 0.6666666666666666],\n",
       " 'brevity_penalty': 0.36787944117144233,\n",
       " 'length_ratio': 0.5,\n",
       " 'translation_length': 6,\n",
       " 'reference_length': 12}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:26:59.944982Z",
     "start_time": "2025-12-08T21:26:58.412421Z"
    }
   },
   "cell_type": "code",
   "source": "bert_result = bertscore.compute(predictions=[predicted_sentence], references=[reference_sentence], lang=\"en\") # model_type='microsoft/deberta-xlarge-mnli' predolgo trae koga se koristi ovoj model_type",
   "id": "bb2d2be37b087af7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:26:59.975816Z",
     "start_time": "2025-12-08T21:26:59.961518Z"
    }
   },
   "cell_type": "code",
   "source": "bert_result",
   "id": "db876193baf7c5b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': [0.9461432695388794],\n",
       " 'recall': [0.90846848487854],\n",
       " 'f1': [0.9269232153892517],\n",
       " 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.57.3)'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Probuvanje so razlichni hiperparametri(learning rate i epochs)",
   "id": "aa89f63adbf85d09"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "lr=0.0001",
   "id": "b5ccb2bc721c1c50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)",
   "id": "60c61fd43cdb8d4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, collate_fn=data_collator)",
   "id": "9bc38adddcc7296a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optimizer = AdamW(model.parameters(), lr=0.0001)",
   "id": "d7b55503e3f5fa9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_transformer(model, train_loader, optimizer, 5, device=device)",
   "id": "df3615f41ea83e10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predicted_sentence = decode_with_transformer(negative[0], tokenizer, model)\n",
    "predicted_sentence"
   ],
   "id": "1993151efaf2ae3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "reference_sentence = positive[0]\n",
    "reference_sentence"
   ],
   "id": "5c36e663825324f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "bleu.compute(predictions=[predicted_sentence], references=[reference_sentence])",
   "id": "c17bd69ac3d76793"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "bert_result = bertscore.compute(predictions=[predicted_sentence], references=[reference_sentence],\n",
    "                                lang=\"en\")  # model_type='microsoft/deberta-xlarge-mnli' predolgo trae koga se koristi ovoj model_type"
   ],
   "id": "46e3bce394115cbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "bert_result",
   "id": "99192738ba149715"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "lr=0.0001 epochs = 10",
   "id": "4232c18882be9d69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)",
   "id": "71dbbfefd0166a3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, collate_fn=data_collator)\n",
    "optimizer = AdamW(model.parameters(), lr=0.0001)"
   ],
   "id": "bde688dbdcd9dcb9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_transformer(model, train_loader, optimizer, 10, device=device)",
   "id": "70e819b27bed641"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predicted_sentence = decode_with_transformer(negative[0], tokenizer, model)\n",
    "predicted_sentence"
   ],
   "id": "f5976e262f5af76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "reference_sentence = positive[0]\n",
    "reference_sentence"
   ],
   "id": "506e408418a4ee98"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "bleu.compute(predictions=[predicted_sentence], references=[reference_sentence])",
   "id": "6076834688425e30"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "bert_result = bertscore.compute(predictions=[predicted_sentence], references=[reference_sentence],\n",
    "                                lang=\"en\")  # model_type='microsoft/deberta-xlarge-mnli' predolgo trae koga se koristi ovoj model_type"
   ],
   "id": "35474c834ac5fd1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "bert_result",
   "id": "e7393b2f0ee39f27"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "lr=0.001 epochs=3",
   "id": "89b7615ec1bcec93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)",
   "id": "fdcfb9fbd1ba754b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, collate_fn=data_collator)",
   "id": "214cfb61ecea747f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optimizer = AdamW(model.parameters(), lr=0.001)",
   "id": "9648b9314f4e58d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_transformer(model, train_loader, optimizer, 3, device=device)",
   "id": "cad2da516dd1c10d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predicted_sentence = decode_with_transformer(negative[0], tokenizer, model)\n",
    "predicted_sentence"
   ],
   "id": "f8c8e54c78d135ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "reference_sentence = positive[0]\n",
    "reference_sentence"
   ],
   "id": "6f5586aaebd5ce26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "bleu.compute(predictions=[predicted_sentence], references=[reference_sentence])",
   "id": "b35af4c1e83d8d10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "bert_result = bertscore.compute(predictions=[predicted_sentence], references=[reference_sentence],\n",
    "                                lang=\"en\")  # model_type='microsoft/deberta-xlarge-mnli' predolgo trae koga se koristi ovoj model_type"
   ],
   "id": "587de1c85eda6934"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "bert_result",
   "id": "cdc68e5a87538e63"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Flan-t5",
   "id": "f07961e215862d20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:27:00.007834Z",
     "start_time": "2025-12-08T21:26:59.992827Z"
    }
   },
   "cell_type": "code",
   "source": "model_name = \"google/flan-t5-small\"",
   "id": "853a6a3997fe4ac8",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:27:00.725597Z",
     "start_time": "2025-12-08T21:27:00.024847Z"
    }
   },
   "cell_type": "code",
   "source": "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)",
   "id": "b9bbda4b934d6ccf",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:27:01.491298Z",
     "start_time": "2025-12-08T21:27:00.742301Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = AutoTokenizer.from_pretrained(model_name)",
   "id": "ef4d9d561268c3aa",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:27:01.537454Z",
     "start_time": "2025-12-08T21:27:01.506874Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset = create_transformers_train_data(negative, positive, tokenizer)",
   "id": "53fef9a9fd94d3a7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arsan\\PycharmProjects\\opj\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:27:01.568104Z",
     "start_time": "2025-12-08T21:27:01.554117Z"
    }
   },
   "cell_type": "code",
   "source": "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)",
   "id": "d27cf2f1127b9cc4",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:27:01.599562Z",
     "start_time": "2025-12-08T21:27:01.584543Z"
    }
   },
   "cell_type": "code",
   "source": "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, collate_fn=data_collator)",
   "id": "31d1d42f5defff62",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:27:01.630339Z",
     "start_time": "2025-12-08T21:27:01.615304Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer = AdamW(model.parameters(), lr=0.001)",
   "id": "24b41466eb4cce5",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:27:07.301385Z",
     "start_time": "2025-12-08T21:27:01.646066Z"
    }
   },
   "cell_type": "code",
   "source": "train_transformer(model, train_loader, optimizer, 5, device=device)",
   "id": "420b1bc420552f3b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 2.6183\n",
      "Epoch 2/5, Loss: 2.0917\n",
      "Epoch 3/5, Loss: 1.8857\n",
      "Epoch 4/5, Loss: 1.7017\n",
      "Epoch 5/5, Loss: 1.5556\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:27:07.629381Z",
     "start_time": "2025-12-08T21:27:07.317339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predicted_sentence = decode_with_transformer(negative[0], tokenizer, model)\n",
    "predicted_sentence"
   ],
   "id": "30a591cb53756b4e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arsan\\PycharmProjects\\opj\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ever since joes has changed hands'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:27:07.661004Z",
     "start_time": "2025-12-08T21:27:07.646644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reference_sentence = positive[0]\n",
    "reference_sentence"
   ],
   "id": "44e9c9564b7dc1d7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ever since joes has changed hands it's gotten better and better.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:27:07.707957Z",
     "start_time": "2025-12-08T21:27:07.692945Z"
    }
   },
   "cell_type": "code",
   "source": "bleu.compute(predictions=[predicted_sentence], references=[reference_sentence])",
   "id": "e9dbf7ae02c204a9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.36787944117144233,\n",
       " 'precisions': [1.0, 1.0, 1.0, 1.0],\n",
       " 'brevity_penalty': 0.36787944117144233,\n",
       " 'length_ratio': 0.5,\n",
       " 'translation_length': 6,\n",
       " 'reference_length': 12}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:27:07.755291Z",
     "start_time": "2025-12-08T21:27:07.724094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bert_result = bertscore.compute(predictions=[predicted_sentence], references=[reference_sentence],\n",
    "                                lang=\"en\")  # model_type='microsoft/deberta-xlarge-mnli' predolgo trae koga se koristi ovoj model_type"
   ],
   "id": "2de6ec7e3dcf7b3d",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T21:27:53.405360Z",
     "start_time": "2025-12-08T21:27:53.389344Z"
    }
   },
   "cell_type": "code",
   "source": "bert_result",
   "id": "d577118e8c15c390",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': [0.9449430108070374],\n",
       " 'recall': [0.9070550203323364],\n",
       " 'f1': [0.9256114363670349],\n",
       " 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.57.3)'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "lr=0.0001",
   "id": "1ab45813eeb72eab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)",
   "id": "45db45e33b25eeb3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, collate_fn=data_collator)",
   "id": "2e390ecfca7b84bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optimizer = AdamW(model.parameters(), lr=0.0001)",
   "id": "fbd522fca0bdce9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_transformer(model, train_loader, optimizer, 5, device=device)",
   "id": "d6f5c45374c593f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predicted_sentence = decode_with_transformer(negative[0], tokenizer, model)\n",
    "predicted_sentence"
   ],
   "id": "61220438ee7253ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "reference_sentence = positive[0]\n",
    "reference_sentence"
   ],
   "id": "9b9368cb7380522"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "bleu.compute(predictions=[predicted_sentence], references=[reference_sentence])",
   "id": "34e705c970ac2575"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "bert_result = bertscore.compute(predictions=[predicted_sentence], references=[reference_sentence],\n",
    "                                lang=\"en\")  # model_type='microsoft/deberta-xlarge-mnli' predolgo trae koga se koristi ovoj model_type"
   ],
   "id": "dcb531a57733d06b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "bert_result",
   "id": "2d184da183be2fe5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "lr=0.0001 epochs=10",
   "id": "77a9aa2b712f58ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)",
   "id": "4d49327406bcbf84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, collate_fn=data_collator)",
   "id": "8ddec6c901cc0c89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optimizer = AdamW(model.parameters(), lr=0.0001)",
   "id": "a77b4799ab57f17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_transformer(model, train_loader, optimizer, 10, device=device)",
   "id": "1a472fa50da61a4e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predicted_sentence = decode_with_transformer(negative[0], tokenizer, model)\n",
    "predicted_sentence"
   ],
   "id": "1fcec3fbdb2a47f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "reference_sentence = positive[0]\n",
    "reference_sentence"
   ],
   "id": "2611c1b56c15c5dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "bleu.compute(predictions=[predicted_sentence], references=[reference_sentence])",
   "id": "a700906857c16fcb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "bert_result = bertscore.compute(predictions=[predicted_sentence], references=[reference_sentence],\n",
    "                                lang=\"en\")  # model_type='microsoft/deberta-xlarge-mnli' predolgo trae koga se koristi ovoj model_type"
   ],
   "id": "63d428491cb65893"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "bert_result",
   "id": "e1c37d37562a32b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "lr=0.001 epochs=3",
   "id": "58b3cfb140fe6acb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)",
   "id": "bd9b3bea5a031b15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, collate_fn=data_collator)",
   "id": "c99447aa68b771f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optimizer = AdamW(model.parameters(), lr=0.001)",
   "id": "539ed264f2ab1249"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_transformer(model, train_loader, optimizer, 3, device=device)",
   "id": "240ada70269640b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predicted_sentence = decode_with_transformer(negative[0], tokenizer, model)\n",
    "predicted_sentence"
   ],
   "id": "5d4e388814c69baa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "reference_sentence = positive[0]\n",
    "reference_sentence"
   ],
   "id": "f079bb8b3ca62dd7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "bleu.compute(predictions=[predicted_sentence], references=[reference_sentence])",
   "id": "37d6b44ef1c5355f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "bert_result = bertscore.compute(predictions=[predicted_sentence], references=[reference_sentence],\n",
    "                                lang=\"en\")  # model_type='microsoft/deberta-xlarge-mnli' predolgo trae koga se koristi ovoj model_type"
   ],
   "id": "3c4a9b1c60d375e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "bert_result",
   "id": "2a8d05737a704c85"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
